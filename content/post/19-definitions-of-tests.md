---
title: "ความน่าปวดหัวของ Test ในระดับต่างๆ"
date: 2018-01-12T12:04:02+07:00
lastmod: 2018-01-12T12:04:02+07:00
draft: true
tags: ["CI", "CD"]
categories: ["Continuous Delivery"]
---

![Photo by Joanna Kosinska on Unsplash](/img/covers/photo-01.jpg)

ช่วงนี้ขึ้นโปรเจ็คใหม่ ในทีมเลยมีการคุยกันเรื่องเทสต์เยอะมาก

โดยทีมก่อนๆที่ผมเจอมาจะคุยกันเรื่อง "เขียนเทสต์ให้มากขึ้น" หรือเรื่อง "Coverage" (เถียงกันว่าจะเอากี่ %)

แต่ทีมปัจจุบันนี่คุยกันเรื่องทำยังไงให้ "เขียนเทสต์ให้น้อยลง"  โดยให้ได้ผลเท่าเดิม

สาเหตุที่คุยกันเรื่องนี้เป็นหลัก เป็นเพราะว่าเทสต์ปัจจุบันเยอะมาก ทำให้มีปัญหาเรื่องที่ใช้ในการรันเทสต์,  และการดูแลรักษาเทสต์

หลังจากนั่งคุยกันสักพัก หนึ่งในปัญหาแรกที่เจอ ก็คือนิยามชื่อเรียก Test แต่ละแบบไม่ตรงกัน เพราะเรามีสมาชิกใหม่หลายคน แต่ละคนก็เรียกกันคนละแบบ

บทความนี้จะกล่าวถึงนิยามต่างๆของ Test โดยพุ่งประเด็นไปที่นิยามอันคลุมเครือเป็นหลักครับ

> บทความนี้อนุมานว่าผู้อ่านเคยเขียนเทสต์ในระดับต่างๆ (ex. Unit, Component, Integration, Acceptance) และมีเข้าใจว่า Continuous Integration (CI) คืออะไร

<!--more-->

# คุณสมบัติที่สำคัญของเทสต์

ก่อนจะเข้าถึงเทสต์แต่ละชนิด ผมขอพูดถึงคุณสมบัติ 6 อย่างที่สำคัญก่อนครับ

**1. คุณค่า (Value)** ก่อนอื่นเราต้องถามตัวเองก่อนว่าเขียนเทสต์เพื่ออะไร บางคนจะตอบแบบกำปั้นทุบดินว่าเพื่อตรวจสอบความถูกต้องของระบบ แต่โปรแกรมเมอร์ที่มีประสบการณ์หลายคนอาจจะไม่เห็นด้วยเสียทีเดียว ตัวอย่างเช่น

* คนที่ทำ Test-Driven-Development (TDD) อาจจะมองประโยชน์ในเรื่องของการออกแบบโค้ดให้มี Interface และจุดประสงค์ของคลาสชัดเจน (Loose Couple, High Cohesion)
* บางคนก็จะมองว่า Testing คือ Documentation อย่างหนึ่ง
* บางคนอาจจะมองว่าเทสต์คือการสื่อสารระหว่างผู้ใช้กับโปรแกรมเมอร์ด้วยซ้ำ (เช่น กรณีของ Behavior-Driven-Development)

ในบทความนี้ ผมจะมุ่งเน้นไปที่คุณค่าเดียว คือการตรวจสอบความถูกต้องของระบบ เพื่อไม่ให้บทความยาวไปถึงอ่าวอันดามัน

เทสต์ที่มีคุณค่าสูง จะต้องตรวจสอบบั๊กแม่นยำ มีโอกาสที่บั๊กหลุดรอดจากการตรวจต่ำ และมีเวลาตรวจเจอ ก็จะต้องเป็นบั๊กจริงๆ ไม่ใช่ False alarm หรือเพราะว่ามีคนเปลี่ยนชื่อ Method แล้วลืมแก้เทสต์

**2. ความเร็ว (Fast)** ทีมที่ทำ Continuous Integration (CI)/Continuous Delivery (CD) ในระดับหนึ่ง จะประสบปัญหาเรื่องเทสต์รันนานมาก การที่เทสต์ใช้เวลารันนานนั้นจะต้องจ่ายด้วย Productivity ของทีม

ค่าใช้จ่ายส่วนแรกมาจากการที่โปรแกรมเมอร์จะไม่ยอมรันเทสต์ให้ครบก่อน Push โค้ด  ใครที่เคยเขียน End-To-End Test จะรู้ดีว่าถ้าเกิน 100 Test Cases เมื่อไร  เวลารันทีนี่เดินไปชงกาแฟให้ทั้งทีมได้เลย ผลที่ตามมาก็คือจะรันแค่เทสต์ในส่วนที่แก้โค้ดไป หรือแค่ Component นั้นๆ แต่ไม่รันหมด  พอเกิดข้อผิดพลาดขึ้น เทสต์ก็จะไปตายใน Pipeline ติดขัดทั้งทีม ซึ่งทำให้ Productivity ของทีมโดยรวมช้าลงมาก

อย่างที่สอง คือเวลาเทสต์พังใน CI จะหา Commit ที่สร้างปัญหายากมาก ลองนึกภาพว่าเทสต์ทั้งหมดต้องใช้เวลา 2 ชั่วโมงในการรัน ยิ่งปริมาณทีมมีขนาดใหญ่ขึั้น จำนวน Commit ที่เข้าไปใน 2 ชั่วโมงนั้นอาจจะมากกว่า 5 Commits  ซึ่งเวลาพังขึ้นมา จะดีบั้กยากว่ามาจากไหน (เพราะต้องหาจาก 5 commits จากโค้ดของคนอื่นๆที่เราไม่ได้เขียนด้วย) และมักจะเกี่ยงกันว่าใครจะเป็นคนหาบั้ก

เทสต์ที่อยู่ในระดับล่างๆ (Unit Test) จะใช้เวลาในการรันที่เร็วกว่า แต่เทสต์บนๆจะใช้เวลานานมาก (Integration Test) เพราะอาจจะต้องมีการส่งข้อมูลผ่าน Network หรือเซ็ตอัพข้อมูล Database  นี่เป็น Trade-off ที่คนในทีมต้องกำหนดกลยุทธิ์ในการเทสต์ให้ดี

**3. ความไม่สม่ำเสมอ (Flakiness)** Test ในระดับบนๆ ตั้งแต่ Integration Test ขึ้นไป จะมีปัญหาเรื่องความไม่สม่ำเสมอในการรัน ตัวอย่างเช่น

* เทสต์ในระดับ Browser (ex. Selenium) บางคนอาจจะเจออาการว่าเทสต์รันผ่านบ้างไม่ผ่านบ้าง เพราะรีบกดปุ่มในชั้นถัดไปเร็วเกิน หน้า UI ยังเรนเดอร์ใหม่ไม่เสร็จ หรือเทสต์บางตัวรันไม่ผ่าน เพราะขนาดหน้าของ Browser เป็นคนละไซส์และปุ่มไปซ่อนอยู่
* เทสต์ในระดับที่ต้องยิงผ่าน Network  บางทีก็ยิงไม่สำเร็จเพราะเน็ตเวิร์คมีปัญหาพอดี
* เทสต์ในระดับที่ต้องติดต่อกับ Third-party System บางทีระบบเราทำงานถูกต้องแล้ว แต่ระบบที่เรายิง Request ไปขอข้อมูลเกิดพังขึ้นมา หรือรับโหลดมากเกินไปจนตอบบาง Request ไม่ทัน

ความไม่สม่ำเสมอนั้นสร้างปัญหาให้กับ CD มาก เพราะเราจะไม่สามารถปล่อยให้โค้ดไหลผ่าน Pipeline ไปบน Production ได้โดยอัตโนมัติ ต้องมานั่งเช็คว่าเทสต์ที่พังนี่พังจริงๆหรือเพราะ Flakiness

**4. ความเปราะบาง (Brittleness)** คือแก้โค้ดที เทสต์พังเป็นยวง ต้องแก้เยอะมาก ความเปราะบางของเทสต์จะมีผลต่อค่าใช้จ่ายในการดูแลรักษา

เทสต์ที่มีปัญหานี้มักจะเป็นโค้ดที่ถูกออกแบบมาไม่ดี เช่น Unit Test ของโค้ดที่ไม่ได้ออกแบบ Class ให้ดี ทำให้ต้องเปลี่ยน Public Interface บ่อย พอเปลี่ยนทีเทสต์ก็ต้องเปลี่ยนไปด้วย หรือเปิด Public Interface ในส่วนที่ไม่ควรจะเปิด ทำให้เวลา Refactor ส่วนที่ควรจะเป็น Internal Implementation ที เทสต์พังพินาจราพณาสูร

ส่วนอีกระดับที่มีปัญหาบ่อยคือ UI เพราะเวลาเปลี่ยน UI ทีนึง ID หรือ Class ที่ใช้หา Element เปลี่ยน โปรแกรมเมอร์ดันแก้เทสต์โค้ดไม่หมด ทำให้เทสต์ไปค้น ID เดิม วิธีนี้อาจจะแก้ได้ด้วย Page Object Pattern แต่ถ้าโปรดักต์มีการเปลี่ยน UI บ่อยๆหรือทำ A/B Testing ในระดับของ UI ปัญหานี้จะหลีกเลี่ยงไม่ได้ ทีมคงได้แต่ลด Test ที่อยู่ในระดับนี้ให้น้อยที่สุด แล้วไปทดสอบ Permutation หรือ Edge case ในระดับล่างๆแทน

**5. ความง่ายในการหาต้นตอ (Failure Isolation)** ตัวอย่างที่ดีคือ Unit Test ที่พัง เราจะรู้เลยว่าน่าจะเป็น Class หรือ Function ไหน ในกรณีอะไร ซึ่งบางครั้งแค่เห็นชื่อเทสต์ที่พังก็จะรู้เลยว่าต้องไปเช็คโค้ดบรรทัดไหน

ตัวอย่างที่แย่ได้แก่ User Acceptance Test พอไม่ผ่านทีนึง เราอาจจะได้ดีบั้กกันข้ามเซอร์วิซกันหลายวัน กว่าจะเจอว่าปัญหามากบรรทัดไหน

ส่วนใหญ่ความง่ายในการหาต้นตอจะลดลงเมื่อเทสต์ขึ้นมาในระดับที่สูงขึ้นเรื่อยๆอย่างหลีกเลี่ยงได้ยาก พอเทสต์ขึ้นมาถึงระดับที่ต้องยิงข้าม Service แล้ว ส่วนใหญ่จะต้องพึ่ง Log ในการแก้ปัญหากัน และต้องใช้ความเข้าใจในระบบที่ดีบั้กสูงมาก

# Unit Test

class, method, function?

ข้อดี เร็ว รู้ว่าพังตรงไหนชัดเจน
ข้อเสีย ไม่ได้ควบคุมอะไรเลย

Test public behavior เพื่อไม่ให้ Brittle

TDD เป็นการออกแบบว่าต้องเขียนเทสต์

ควรจะเป็น 100% ไหม?

## Test double
stub mock, etc.



# Component Test

isolate component, stub & driver

granularity    (one API, one high-order Component)

BE or Frontend?

Putting permutation at the lowest layer

which level will you mock? (Don't mix it w/ unit test)

# Integration

horrible naming - Integral between component we own? or integrate with 3rd party system?

It might be stub/mock, unclear

Set up clear testing?

# System testing
Usually more than one component? what is system?

which is stub?

# End2End
Staging against which?

flaky, fricking slow

# Regression Testing
how can we ensure?

at higher level?

on stage or on prod?

# (User) Acceptance Testing
Enduser involved

สัญลักษณ์ของ Silo

bad smell

verification of requirement?

prototyping?

# เทสต์ยิ่งสูง ยิ่งมีคุณค่า แต่ราคายิ่งแพง
