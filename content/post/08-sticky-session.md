---
title: "ปัญหาของ Sticky Session"
date: 2017-10-24T12:04:02+07:00
lastmod: 2017-10-24T12:04:02+07:00
draft: false
tags: ["scalability", "loadbalancer", "sticky session", "design"]
categories: ["Scalability"]
---



![Photo by Denys Nevozhai, from Unsplash.com](/img/covers/traffic-01.jpg)

ใครที่เคยใช้ Load Balancer (LB) คงจะเคยได้ยินคำว่า Sticky Session (หรือ Session Affinity) กันมาบ้าง

ไอเดียคือ หากเรามีเซอร์เวอร์ 3 ตัว ชื่อว่า S1, S2, และ S3 วางอยู่ข้างหลัง LB  แล้วมีผู้ใช้ส่ง Request เข้ามายังเว็บเรา

{{% imgcenter src="/img/diagrams/loadbalancer.png" caption="Load Balancer with 3 servers" %}}

ในครั้งแรก Request อาจถูกส่งไปให้ S1 แต่พอผู้ใช้ไปหน้าถัดไป หรือดึงข้อมูลครั้งถัดๆไป LB อาจส่ง Request นั้นไปยัง S2 หรือ S3 แทน

หากเราเปิด Sticky Session ใน LB จะส่ง Request จากผู้ใช้คนเดิมไปยัง S1 ตลอดระยะเวลาที่ผู้ใช้ติดต่อกับเรา โดยไม่ส่งไปที่ S2 หรือ S3 เลย

ในบทความนี้ เราจะมาทำความเข้าใจว่า Sticky Session ทำงานยังไง และการใช้ Sticky Session อาจนำมาซึ่งปัญหาอะไรได้บ้าง

<!--more-->

# การทำงานของ Sticky Session

สมมติว่าเราเป็น LB เราจะรู้ได้อย่างไรว่า Request นี้มาจากผู้ใช้คนไหน?

วิธีการที่ LB ใช้ คือทำการใส่ค่า Session Id ลงไปใน Cookie ของ Response ของ Request ที่ได้รับมาครั้งแรก แล้วจำค่าเอาไว้ว่า Session Id นี้ถูกส่งไปที่ S1

หลังจากนั้น ฝั่ง Client (เช่น เว็บบราวเซอร์) จะเก็บค่า Session Id และใส่ใน Header ของ Request ถัดๆไป

พอ LB ได้รับ Request ถัดมา ก็สามารถเช็ค Header ได้ว่าคราวที่แล้วเราส่ง Request ที่มี Session Id นี้ไปยังเซอร์เวอร์ไหน

วิธีนี้การันตีได้ว่า LB จะส่ง Session Id ไปยัง S1 ตลอด

Note: LB บางตัวสามารถทำงานโดยการเช็คผ่าน IP Address แทนการใช้ Cookie  แต่วิธีนี้อันตรายมากๆ เพราะ[เราไม่มีทางการันตีได้ว่า IP ของแต่ละผู้ใช้จะต่างกัน](http://www.chaosincomputing.com/2012/05/sticky-sessions-are-evil/) เป็นไปได้ว่าผู้ใช้จากบริษัทหนึ่งมาจาก Proxy Server หรือ NAT เดียวกัน ผลที่ตามมาคือเซอร์เวอร์นึงจะรับ Request จากผู้ใช้ของบริษัทนี้ทั้งหมด


# ปัญหาของ Sticky Session

ในโลกแห่งความจริงอันโหดร้าย เซอร์เวอร์ตายเป็นเรื่องธรรมดา

เวลาเซอร์เวอร์ตาย LB จะรู้ได้เพราะมันจะทำการยิง Health Check ไปยังเซอร์เวอร์เป็นระยะๆ

{{% imgcenter src="/img/diagrams/loadbalancer-s1-die.png" caption="S1 cannot be reached by Load Balancer" %}}

พอ Health Check ที่ยิงไปไม่มีอะไรตอบกลับมาจาก S1  เจ้า LB ก็จะทำการตัด S1 ออกจากกอง เวลามี Request ใหม่ๆมาก็ส่งไปให้ S2 กับ S3 แทน

แต่หาก Request ที่ส่งมา ดันมี Session Id ที่เคยส่งไปให้กับ S1 ล่ะ?

กรณีนี้ LB ไม่มีทางเลือก ต้องส่ง Request นั้นไปยัง S2 หรือ S3 อยู่ดี เพราะ S1 ตายไปเรียบร้อยแล้ว

**จะเห็นได้ว่า แม้เราจะมีการเปิด Sticky Session ไว้แล้ว โปรแกรมจะต้องรองรับกรณีที่ Session ไม่ได้ Sticky อยู่ดี**

โปรแกรมจะคาดหวังว่า Request จากผู้ใช้เดียวกันจะมายังเซอร์เวอร์ตัวเดียวอยู่เสมอไม่ได้

ลองนึกภาพว่าเราทำเว็บขายของ แล้วเก็บของที่ลูกค้าเลือกใส่ตะกร้าเอาไว้ใน S1  พอ S1 ตาย Request ใหม่ถูกส่งไปยัง  S2

S2 ก็งงสิ เพราะไม่มีในตะกร้าเก็บไว้

กรณีร้ายที่สุด คือไอ้ Request นี้เป็นคำสั่งที่ให้เช็คเอ้าท์จ่ายเงินพอดี ถ้าโปรแกรมไม่ได้เช็คกรณีนี้ไว้ อาจจะเกิดอาการแปลกๆ เช่น ทำการเช็คเอ้าท์แบบไม่มีของ แต่ตัดเงินเต็มจำนวน

ซึ่งก็กลายเป็นว่า เราต้องมาเขียนดักกรณีนี้ในทุกฟังก์ชั่น ว่าถ้าเกิดเราได้ Request ใหม่มาจากเซอร์เวอร์ที่พึ่งตายไป ให้ทำการแจ้งลูกค้าว่าของคุณหาย ให้ไปเลือกใหม่ นอกจากจะเป็น UX ที่ห่วยแล้ว ยังทำให้โปรแกรมเราซับซ้อนขึ้นมาก

# แทนที่จะพึ่ง Sticky session ให้ทำทุกอย่างให้เป็น Stateless แทน

ในทางปฏิบัติ อย่างน้อยก็ในเลเยอร์ของเว็บเซอร์เวอร์ (Web Server Layer) เราจึงควรออกแบบโปรแกรมให้เป็น Stateless

Stateless คือไม่จำอะไรอยู่ในเว็บเซอร์เวอร์ ถ้าจะจำ ก็ให้เอาไปจำใน Database แทน

ซึ่งหากต้องการความเร็ว ก็ให้เอาไปไว้ใน In-Memory Database  หากไม่ต้องเร็วมาก ก็ใส่ลงใน NoSQL หรือ Relational DB ธรรมดาได้

วิธีนี้อาจจะทำให้ประสิทธิภาพด้อยกว่าการจำข้อมูลไว้ในเว็บเซอร์เวอร์ แต่จะทำให้ระบบสเกลได้ง่ายกว่า


# ถ้าทำ Sticky Session + Stateless ล่ะ?

สมมติว่าเราทำทุกอย่างให้เป็น Stateless แล้ว โดยการใส่ In-Memory Database แยกไว้ให้ S1/S2/S3 ดึงข้อมูลร่วมกันได้

เราจัด Sticky Session เพิ่มด้วย แล้วทำการ Cache ใน S1/S2/S3 เพิ่มลงไปอีกจะดีรึเปล่า?

ถ้าหากข้อมูลที่จะดึง อยู่ใน Cache ของ S1 แล้ว ก็ทำการส่งกลับได้เลย แทนที่จะต้องไปขอข้อมูลจาก In-Memory Database

แม้ว่าจะดูดี แต่ในทางปฏิบัติจริง แม้จะเป็น Stateless แล้ว การใช้ Sticky Session ก็ยังมีปัญหาอยู่ดี ตัวอย่างเช่น

## 1. Cache Invalidation
ถ้าข้อมูลที่จะดึงถูกแก้ใน In-Memory Database ผ่านทาง S2 (จากผู้ใช้อีกคน)  S1 อาจจะส่งข้อมูลเก่าไปให้ผู้ใช้ กรณีนี้รับได้รึเปล่า?

ถ้าไม่ เราก็ต้องทำแอพพลิเคชั่นของเราให้มีการ Invalidate Cache ตลอดการแก้ข้อมูล ซึ่งหากมีการแก้ข้อมูลบ่อยๆ ประสิทธิภาพที่ได้ อาจจะไม่คุ้มค่าการเวลาทีต้องเสียไปในการ Invalidate Cache

## 2. Unbalanced Load
หาก Session ของผู้ใช้แต่ละคนยาวไม่เท่ากัน อาจเป็นไปได้ที่ S1 จะมีผู้ใช้ค้างอยู่จำนวนเยอะกว่า  

ในขณะที่ S2 (ซึ่งเผอิญไปเจอผู้ใช้ส่วนใหญ่ใช้งานไม่นาน)นั้นโล่งสนิท  

ทำให้การกระจาย Load ไม่ Balance อย่างที่เราต้องการ กรณีนี้จะทำให้ Capacity ที่เรารองรับได้ลดลงกว่าที่ควรจะเป็น

กรณีอาจจะเกิดขึ้นได้หาก Session ของผู้ใช้บางคนยาวมาก (เช่นหลายชั่วโมง) Session ยาวๆพวกนี้จะค้างอยู่ในระบบนานพอที่จะทำให้เกิด Unbalanced Load ได้ ถ้าคิดว่าเว็บไซต์ของเราอาจมี Session ที่ค้างไว้นาน กรณีนี้อาจจะไม่เหมาะนัก

## 3. ปัญหาเวลาเซอร์เวอร์บางตัวดาวน์

หากเราต้องการหยุดเซอร์เวอร์ตัวหนึ่งชั่วคราว (อาจจะเพื่ออัพเดตซอฟต์แวร์ หรือเซอร์เวอร์มีปัญหาต้อง restart) จะเกิดอะไรขึ้น?

Request ปริมาณ 1/3 ที่เข้ามา S1 จะต้องถูกกระจายไปยัง S2/S3 ซึ่งไม่มี Cache  ซึ่งจะนำมาซึ่งปัญหา 2 อย่าง

1. Latency ของ Request 1/3 ส่วนจะพึ่งขึ้นอย่างมีนัยยะสำคัญ เพราะต้องไปดึงข้อมูลมาจาก In-Memory DB ข้างนอกแทนที่จะใช้ใน Cache ได้เลย ไอ้การพุ่งขึ้นโดยไม่ได้นัดหมายนี้เป็น False alarm ซึ่งอาจจะทำให้ทีม Operation ต้องแหกขี้ตาขึ้นมากลางดึกได้ เป็นที่สาบแช่งของทีมว่าใครดีไซน์ระบบแบบนี้วะ
1. ปริมาณ Request ที่สูงขึ้นนี้ อาจทำให้ขนาดของ Cache ใน S2/S3 ไม่พอรองรับปริมาณข้อมูลของผู้ใช้ทั้งหมด ลองนึกภาพว่าเราเตรียม Cache ไว้ให้พอดีสำหรับผู้ใช้แค่ 1/3 อยู่ดีๆ ปริมาณข้อมูลดันเพิ่มเป็น 1/2 นั่นแปลว่าจะมีข้อมูล 1/5 (1/2-1/3) ที่ไม่มีที่เก็บใน Cache และต้องถูกเตะออกไป ซึ่งจะทำให้เกิดการ Cache miss บ่อยขึ้น ส่งผลต่อความเสถียรของระบบอีก

บางคนอาจจะบอกว่า งั้นทำไมเราก็เปิดเซอร์เวอร์ S4 ขึ้นมาช่วยสิ โดยเซ็ตค่าให้เปิดอัตโนมัติเวลามี S1-S3 เดี้ยงไป

ตรงนี้อาจจะช่วยได้หน่อยหนึ่ง แต่ก็ยังมีปัญหาอยู่ดี เพราะ Cache ที่ S1 เก็บไว้นั้นไม่มีอยู่ใน S4  แถม LB เองก็อาจไม่ฉลาดพอ ที่จะส่ง Session พวกนั้นเข้า S4 ให้หมดโดยไม่เข้า S2 หรือ S3 เลย

# สรุป
แม้คอนเซ็บ Sticky Session จะฟังดูดีมาก แต่มีปัญหาใหญ่ๆเยอะในระบบจริง ถึงฝั่งเซอร์เวอร์จะเป็น Stateless ก็ตาม

ปัญหาแรกคือโปรแกรมที่เขียนจะต้องจัดการทั้งกรณีที่ Sticky session เป็น Request เก่า และ  Request ใหม่ ทำให้โปรแกรมซับซ้อนมากขึ้น ใช้เวลานานขึ้น

ปัญหาถัดมาคือเรื่องการกระจายของ Load ที่อาจไม่สมดุล เพราะผู้ใช้บางคนอาจมี Session ที่ยาวค้างอยู่ในเซอร์เวอร์หนึ่งๆนาน

และปัญหาสุดท้าย คือเวลามีเซอร์เวอร์ตัวหนึ่งหยุดทำงาน เซอร์เวอร์ที่เหลือจะทำงานหนักขึ้นชั่วคราว ซึ่งอาจก่อให้เกิดปัญหากับ Operation ได้

โดยส่วนตัวแล้วผมไม่แนะนำให้ใช้ Sticky Session เลย เพราะพอระบบสเกลขึ้นรับโหลดเยอะๆแล้วผลดีไม่คุ้มกับผลเสีย
